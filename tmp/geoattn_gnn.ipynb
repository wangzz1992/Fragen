{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import argparse\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "# import torch_geometric\n",
    "# assert not torch_geometric.__version__.startswith('2'), 'Please use torch_geometric lower than version 2.0.0'\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from models.surfgen import SurfGen\n",
    "from utils.datasets import *\n",
    "from utils.transforms import *\n",
    "from utils.misc import *\n",
    "from utils.train import *\n",
    "from utils.datasets.surfdata import SurfGenDataset\n",
    "from time import time\n",
    "from utils.train import get_model_loss\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--config', type=str, default='/home/haotian/molecules_confs/Protein_test/Pocket2Mol-main/configs/train.yml')\n",
    "parser.add_argument('--device', type=str, default='cpu')\n",
    "parser.add_argument('--logdir', type=str, default='/home/haotian/molecules_confs/Protein_test/Pocket2Mol-main/logs')\n",
    "args = parser.parse_args([])\n",
    "base_path = '/home/haotian/Molecule_Generation/SurfGen'\n",
    "args.config = os.path.join(base_path, 'configs/train_surf.yml')\n",
    "args.logdir = os.path.join(base_path, 'logs')\n",
    "config = load_config(args.config)\n",
    "config_name = os.path.basename(args.config)[:os.path.basename(args.config).rfind('.')]\n",
    "seed_all(config.train.seed)\n",
    "config.dataset.path = os.path.join(base_path, 'data/crossdocked_pocket10')\n",
    "config.dataset.split = os.path.join(base_path, 'data/split_by_name.pt')\n",
    "log_dir = get_new_log_dir(args.logdir, prefix=config_name)\n",
    "ckpt_dir = os.path.join(log_dir, 'checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_featurizer = FeaturizeProteinAtom()\n",
    "ligand_featurizer = FeaturizeLigandAtom()\n",
    "masking = get_mask(config.train.transform.mask)\n",
    "composer = AtomComposer(protein_featurizer.feature_dim, ligand_featurizer.feature_dim, config.model.encoder.knn)\n",
    "edge_sampler = EdgeSample(config.train.transform.edgesampler)\n",
    "cfg_ctr = config.train.transform.contrastive\n",
    "contrastive_sampler = ContrastiveSample(cfg_ctr.num_real, cfg_ctr.num_fake, cfg_ctr.pos_real_std, cfg_ctr.pos_fake_std, config.model.field.knn)\n",
    "transform = Compose([\n",
    "    RefineData(),\n",
    "    LigandCountNeighbors(),\n",
    "    protein_featurizer,\n",
    "    ligand_featurizer,\n",
    "    masking,\n",
    "    composer,\n",
    "\n",
    "    FocalBuilder(),\n",
    "    edge_sampler,\n",
    "    contrastive_sampler,\n",
    "])\n",
    "\n",
    "dataset, subsets = get_dataset(\n",
    "    config = config.dataset,\n",
    "    transform = transform,\n",
    ")\n",
    "dataset, subsets = get_dataset(\n",
    "    config = config.dataset,\n",
    "    transform = transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, subsets = get_dataset(\n",
    "    config = config.dataset,\n",
    "    transform = transform,\n",
    ")\n",
    "train_set, val_set = subsets['train'], subsets['test']\n",
    "follow_batch = []\n",
    "collate_exclude_keys = ['ligand_nbh_list']\n",
    "train_iterator = inf_iterator(DataLoader(\n",
    "    train_set, \n",
    "    batch_size = config.train.batch_size, \n",
    "    shuffle = True,\n",
    "    num_workers = config.train.num_workers,\n",
    "    pin_memory = config.train.pin_memory,\n",
    "    follow_batch = follow_batch,\n",
    "    exclude_keys = collate_exclude_keys,\n",
    "))\n",
    "val_loader = DataLoader(val_set, config.train.batch_size, shuffle=False, follow_batch=follow_batch, exclude_keys = collate_exclude_keys,)\n",
    "train_loader = DataLoader(train_set, config.train.batch_size, shuffle=False,  exclude_keys = collate_exclude_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = val_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_scatter import scatter_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.invariant import VNLinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_feature = torch.cat([pos.unsqueeze(1),pos.unsqueeze(1)], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_feature = vet_attn_net(vec_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_vec = (vec_feature[edge_index[0]] * vec_feature[edge_index[1]]).sum(-1).sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_vec = sigmoid(alpha_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([297, 13])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_sca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_col = edge_index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_attn_input = 27\n",
    "hidden_sca = 16\n",
    "sca_attn_net = nn.Linear(node_attn_input, hidden_sca)\n",
    "\n",
    "node_sca = data.compose_feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Sigmoid\n",
    "sigmoid = Sigmoid()\n",
    "input_node_vec_dim = 2\n",
    "input_node_sca_dim = 13\n",
    "input_edge_vec_dim = 1\n",
    "input_edge_sca_dim = 4\n",
    "out_dim = 16\n",
    "\n",
    "node_vec_net = VNLinear(input_node_vec_dim,out_dim)\n",
    "node_sca_net = nn.Linear(input_node_sca_dim, out_dim)\n",
    "edge_vec_net = VNLinear(input_edge_vec_dim, out_dim)\n",
    "edge_sca_net = nn.Linear(input_edge_sca_dim, out_dim)\n",
    "sca_attn_net = nn.Linear(input_node_sca_dim*2+1, out_dim)\n",
    "vec_attn_net = VNLinear(input_node_vec_dim, out_dim)\n",
    "mapper = GVPerceptronVN(out_dim,out_dim,out_dim,out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = data.compose_knn_edge_index\n",
    "pos = data.compose_pos\n",
    "node_sca = data.compose_feature\n",
    "edge_sca = data.compose_knn_edge_feature.float()\n",
    "edge_dist = torch.norm(pos[edge_index[0]]-pos[edge_index[1]], dim=-1)\n",
    "edge_vec = (data.compose_pos[edge_index[0]] - data.compose_pos[edge_index[1]]).unsqueeze(-2)\n",
    "node_vec = torch.cat([pos.unsqueeze(1),pos.unsqueeze(1)], dim=-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_sca = torch.cat([node_sca[edge_index[0]], node_sca[edge_index[1]], edge_dist.unsqueeze(-1)], dim=-1)\n",
    "alpha_sca = sca_attn_net(alpha)\n",
    "alpha_vec_hid = vec_attn_net(node_vec)\n",
    "alpha_vec = (alpha_vec_hid[edge_index[0]] * alpha_vec_hid[edge_index[1]]).sum(-1).sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_raw = edge_index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_net = nn.Linear(input_node_sca_dim, out_dim)\n",
    "edge_net = nn.Linear(input_edge_sca_dim, out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7128, 16])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_sca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7128, 16])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_sca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7128, 16])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scatter_softmax(alpha_sca, edge_raw, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_sca_feat = node_net(node_sca)[edge_raw] * edge_net(edge_sca) * scatter_softmax(alpha_sca, edge_raw, dim=0)\n",
    "\n",
    "emb_sca = scatter_sum(node_sca_feat,edge_raw, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "node_sca_hid = node_sca_net(node_sca)[edge_raw].unsqueeze(-1)\n",
    "edge_vec_hid = edge_vec_net(edge_vec)\n",
    "node_vec_hid = node_vec_net(node_vec)[edge_raw]\n",
    "edge_sca_hid =  edge_sca_net(edge_sca).unsqueeze(-1)\n",
    "emb_vec = scatter_add((node_sca_hid * edge_vec_hid + node_vec_hid*edge_sca_hid)*alpha_vec.unsqueeze(-1).unsqueeze(-1), edge_raw, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7128, 16])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_sca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([297, 16, 3])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.3168e+04, -1.3868e+05,  1.7453e+06,  ...,  9.1794e+06,\n",
       "          -5.0587e+04,  1.2143e+07],\n",
       "         [-1.5051e+04, -1.4223e+05,  1.5296e+06,  ...,  9.9887e+06,\n",
       "          -5.3473e+04,  1.2224e+07],\n",
       "         [-1.1724e+04, -1.3098e+05,  1.7133e+06,  ...,  9.3352e+06,\n",
       "          -4.8092e+04,  1.1505e+07],\n",
       "         ...,\n",
       "         [-1.6278e+04, -1.5842e+05,  2.0223e+06,  ...,  9.8644e+06,\n",
       "          -5.8754e+04,  1.3841e+07],\n",
       "         [-1.4820e+04, -1.4958e+05,  1.8701e+06,  ...,  9.1884e+06,\n",
       "          -5.4672e+04,  1.3077e+07],\n",
       "         [-1.4477e+04, -1.4683e+05,  1.8290e+06,  ...,  8.9941e+06,\n",
       "          -5.3496e+04,  1.2857e+07]], grad_fn=<LeakyReluBackward0>),\n",
       " tensor([[[ 2.1365e+04,  3.2876e+04,  3.0362e+04],\n",
       "          [-2.3366e+05, -4.8037e+05, -1.5488e+06],\n",
       "          [ 2.6071e+06,  2.9411e+06, -3.9659e+06],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-2.9457e+05, -2.0850e+05,  3.8137e+05],\n",
       "          [ 1.3829e+06,  2.4427e+06,  6.7921e+06]],\n",
       " \n",
       "         [[ 1.3683e+05, -1.2566e+04,  2.4611e+04],\n",
       "          [-1.9094e+05, -4.0169e+05, -1.3392e+06],\n",
       "          [-2.6106e+06, -5.0019e+06, -1.3801e+07],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-2.0714e+05, -2.2131e+05,  3.6184e+05],\n",
       "          [ 1.3831e+06,  2.5126e+06,  6.8187e+06]],\n",
       " \n",
       "         [[ 1.7119e+04,  7.0196e+04,  1.9617e+04],\n",
       "          [-2.1573e+05, -4.8381e+05, -1.6444e+06],\n",
       "          [ 1.5906e+06,  3.9123e+06, -8.1019e+06],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-3.0992e+05, -1.4362e+05,  3.5249e+05],\n",
       "          [ 1.2798e+06,  2.2245e+06,  6.1585e+06]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-6.3757e+02, -9.4105e+04,  8.2032e+04],\n",
       "          [-2.0960e+05, -4.7186e+05, -1.5061e+06],\n",
       "          [-2.2062e+05,  4.2165e+06, -4.0134e+06],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-1.6301e+05,  2.1661e+03,  3.0716e+05],\n",
       "          [ 1.4418e+06,  2.8508e+06,  7.8243e+06]],\n",
       " \n",
       "         [[ 2.0775e+04,  5.7958e+04,  2.2076e+04],\n",
       "          [-3.9460e+05, -4.4256e+05, -1.4520e+06],\n",
       "          [-5.9604e+05,  1.6142e+06, -7.4367e+05],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-2.5137e+04, -1.6516e+05,  3.2269e+05],\n",
       "          [ 2.0800e+06,  2.3810e+06,  7.3136e+06]],\n",
       " \n",
       "         [[ 3.4463e+04,  3.0369e+04,  2.6763e+04],\n",
       "          [-3.7626e+05, -4.2492e+05, -1.4669e+06],\n",
       "          [ 8.2719e+05,  4.6287e+06, -6.4239e+06],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-1.4251e+05, -3.6157e+05,  4.1386e+05],\n",
       "          [ 1.9674e+06,  2.4108e+06,  7.2036e+06]]], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapper([emb_sca, emb_vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_scatter import scatter_add, scatter_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = scatter_sum((node_sca_hid * edge_vec_hid + node_vec_hid*edge_sca_hid)*alpha_vec.unsqueeze(-1).unsqueeze(-1), edge_raw, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = scatter_add((node_sca_hid * edge_vec_hid + node_vec_hid*edge_sca_hid)*alpha_vec.unsqueeze(-1).unsqueeze(-1), edge_raw, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([297, 16, 3])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7128])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([297, 16, 3])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scatter_add(out, edge_col, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7128, 16, 3])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(node_sca_hid * edge_vec_hid).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7128, 24, 3])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_edge_vec_net(edge_vec).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AtomEmbedding(Module):\n",
    "    def __init__(self, in_scalar, in_vector,\n",
    "                 out_scalar, out_vector, vector_normalizer=20.):\n",
    "        super().__init__()\n",
    "        assert in_vector == 1\n",
    "        self.in_scalar = in_scalar\n",
    "        self.vector_normalizer = vector_normalizer\n",
    "        self.emb_sca = Linear(in_scalar, out_scalar)\n",
    "        self.emb_vec = Linear(in_vector, out_vector)\n",
    "\n",
    "    def forward(self, scalar_input, vector_input):\n",
    "        vector_input = vector_input / self.vector_normalizer\n",
    "        assert vector_input.shape[1:] == (3, ), 'Not support. Only one vector can be input'\n",
    "        sca_emb = self.emb_sca(scalar_input[:, :self.in_scalar])  # b, f -> b, f'\n",
    "        vec_emb = vector_input.unsqueeze(-1)  # b, 3 -> b, 3, 1\n",
    "        vec_emb = self.emb_vec(vec_emb).transpose(1, -1)  # b, 1, 3 -> b, f', 3\n",
    "        return sca_emb, vec_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## atom embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_vec = nn.Linear(1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def forward(self, scalar_input, vector_input):\n",
    "        vector_input = vector_input / self.vector_normalizer\n",
    "        assert vector_input.shape[1:] == (3, ), 'Not support. Only one vector can be input'\n",
    "        sca_emb = self.emb_sca(scalar_input[:, :self.in_scalar])  # b, f -> b, f'\n",
    "        vec_emb = vector_input.unsqueeze(-1)  # b, 3 -> b, 3, 1\n",
    "        vec_emb = self.emb_vec(vec_emb).transpose(1, -1)  # b, 1, 3 -> b, f', 3\n",
    "        return sca_emb, vec_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_emb = pos.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([276, 10, 3])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_vec(vec_emb).transpose(1, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_net = VNLinear(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VNLinear(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, *args, **kwargs):\n",
    "        super(VNLinear, self).__init__()\n",
    "        self.map_to_feat = nn.Linear(in_channels, out_channels, *args, **kwargs)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x: point features of shape [B, N_samples, N_feat, 3]\n",
    "        '''\n",
    "        x_out = self.map_to_feat(x.transpose(-2,-1)).transpose(-2,-1)\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = pos.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec2 = torch.cat([vec,vec], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_net2 = nn.Linear(2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([276, 2, 3])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec2.transpose(-2,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = vec2.transpose(-2,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GVP(nn.Module):\n",
    "    '''\n",
    "    Geometric Vector Perceptron. See manuscript and README.md\n",
    "    for more details.\n",
    "    \n",
    "    :param in_dims: tuple (n_scalar, n_vector)\n",
    "    :param out_dims: tuple (n_scalar, n_vector)\n",
    "    :param h_dim: intermediate number of vector channels, optional\n",
    "    :param activations: tuple of functions (scalar_act, vector_act)\n",
    "    :param vector_gate: whether to use vector gating.\n",
    "                        (vector_act will be used as sigma^+ in vector gating if `True`)\n",
    "    '''\n",
    "    def __init__(self, in_dims, out_dims, h_dim=None,\n",
    "                 activations=(F.relu, torch.sigmoid), vector_gate=False):\n",
    "        super(GVP, self).__init__()\n",
    "        self.si, self.vi = in_dims\n",
    "        self.so, self.vo = out_dims\n",
    "        self.vector_gate = vector_gate\n",
    "        if self.vi: \n",
    "            self.h_dim = h_dim or max(self.vi, self.vo) \n",
    "            self.wh = nn.Linear(self.vi, self.h_dim, bias=False)\n",
    "            self.ws = nn.Linear(self.h_dim + self.si, self.so)\n",
    "            if self.vo:\n",
    "                self.wv = nn.Linear(self.h_dim, self.vo, bias=False)\n",
    "                if self.vector_gate: self.wsv = nn.Linear(self.so, self.vo)\n",
    "        else:\n",
    "            self.ws = nn.Linear(self.si, self.so)\n",
    "        \n",
    "        self.scalar_act, self.vector_act = activations\n",
    "        self.dummy_param = nn.Parameter(torch.empty(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        :param x: tuple (s, V) of `torch.Tensor`, \n",
    "                  or (if vectors_in is 0), a single `torch.Tensor`\n",
    "        :return: tuple (s, V) of `torch.Tensor`,\n",
    "                 or (if vectors_out is 0), a single `torch.Tensor`\n",
    "        '''\n",
    "        if self.vi:\n",
    "            s, v = x\n",
    "            v = torch.transpose(v, -1, -2)\n",
    "            vh = self.wh(v)    \n",
    "            vn = _norm_no_nan(vh, axis=-2)\n",
    "            s = self.ws(torch.cat([s, vn], -1))\n",
    "            if self.vo: \n",
    "                v = self.wv(vh) \n",
    "                v = torch.transpose(v, -1, -2)\n",
    "                if self.vector_gate: \n",
    "                    if self.vector_act:\n",
    "                        gate = self.wsv(self.vector_act(s))\n",
    "                    else:\n",
    "                        gate = self.wsv(s)\n",
    "                    v = v * torch.sigmoid(gate).unsqueeze(-1)\n",
    "                elif self.vector_act:\n",
    "                    v = v * self.vector_act(\n",
    "                        _norm_no_nan(v, axis=-1, keepdims=True))\n",
    "        else:\n",
    "            s = self.ws(x)\n",
    "            if self.vo:\n",
    "                v = torch.zeros(s.shape[0], self.vo, 3,\n",
    "                                device=self.dummy_param.device)\n",
    "        if self.scalar_act:\n",
    "            s = self.scalar_act(s)\n",
    "        \n",
    "        return (s, v) if self.vo else s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "sca = pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = GVP(in_dims=(3,2),out_dims=(6,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([276, 3, 2])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec2_trans = torch.transpose(vec2, -1, -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([276, 2, 3])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec2_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh = nn.Linear(2, 10, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([276, 3, 2])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "vh = wh(vec2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([276, 3, 10])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6624, 16])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_sca.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('carbon')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8cb457098628399098f8244ea6d862b61e5b409c4fe20c91d3202c562013c713"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
